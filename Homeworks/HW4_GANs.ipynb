{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Existanze54/sirius-neural-networks-2024/blob/main/Homeworks/HW4_GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание 4. Собираем свой GAN\n",
        "\n",
        "В этом задании необходимо будет воссоздать архитектуру GAN (Generative Adversarial Networks) модели, состоящую из генератора и дискриминатора. В качестве данных будем использовать стандартный датасете MNIST. Хотим иметь возможность генерировать качественные изображения рукописных цифр по запросу.\n"
      ],
      "metadata": {
        "id": "vDgVEIB-_nUc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZfbqQXAX__6"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "from torch import autograd\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import ToTensor, Normalize, Compose\n",
        "from torchvision.datasets import MNIST # самый обычный MNIST\n",
        "\n",
        "# Загрузка датасета\n",
        "\n",
        "mnist = MNIST(root='data',\n",
        "              train=True,\n",
        "              download=True,\n",
        "              transform=Compose([ToTensor(), Normalize(mean=(0.5,), std=(0.5,))]))"
      ],
      "metadata": {
        "id": "5kgCem5fYTqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Помещаем все значения в диапазон от 0 до 1"
      ],
      "metadata": {
        "id": "nW-2ejddBuH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_random_seed(seed):\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ],
      "metadata": {
        "id": "AVIasFH5j_ZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def denorm(x):\n",
        "    out = (x + 1) / 2\n",
        "    return out.clamp(0, 1)\n",
        "\n",
        "img, label = mnist[0]\n",
        "print('Label: ', label)\n",
        "img_norm = denorm(img)\n",
        "plt.imshow(img_norm[0], cmap='gray')"
      ],
      "metadata": {
        "id": "UnlYBSG-Yd_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "ag5LNSK-Yl9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = torch.utils.data.DataLoader(mnist,\n",
        "                                          batch_size=64,\n",
        "                                          drop_last=True, # чтобы не было проблем с незаполненным последним батчем при работе с CNN\n",
        "                                          shuffle=True)"
      ],
      "metadata": {
        "id": "NLLgyySAYr_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 1. Простейший GAN\n",
        "### Что такое GAN?\n",
        "\n",
        "В 2014 году, [Goodfellow et al.](https://arxiv.org/abs/1406.2661) опубликовали метод для тренировки генеративных моделей, который называется Generative Adversarial Networks (GANs).\n",
        "\n",
        "Давайте воспроизведем архитектуру из этой статьи.\n",
        "\n",
        "### Для начала вспомним в общем архитектуру GAN.\n",
        "Генератор создает \"изображения\" из случайного шума и подает результат на вход дискриминатора. Дискриминатор обучается на реальных изображениях и на изображениях, сгенерированных генератором, выдает свою оценку, и градиенты используются для обновления весов как дискриминатора, так и генератора. Помним, что дискриминатор может быть слишком строгим, поэтому его можно обучать реже, либо сделать чуть лояльнее к генератору, используя дропауты.\n",
        "\n",
        "<img src=\"https://data.bioml.ru/htdocs/courses/bioml/neural_networks/gan/img/gan_scheme.png\" alt=\"Drawing\" width= \"800px;\"/>"
      ],
      "metadata": {
        "id": "dlZWQyHRCMoC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поскольку мы хотим иметь возможность генерировать изображения цифр по запросу, мы будем и генератору и дискриминатору передавать метку класса. То есть будем использовать архитектуру GAN с условиями (cGAN).\n",
        "\n",
        "\n",
        "<img src=\"https://data.bioml.ru/htdocs/courses/bioml/neural_networks/gan/img/gan_conditional_scheme.png\" alt=\"Drawing\" width= \"800px;\"/>"
      ],
      "metadata": {
        "id": "UWytIB8wGZ27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Дискриминатор\n",
        "Реализуйте архитектуру дискриминатора по приведенной ниже схеме\n",
        "\n",
        "1. Полносвязный линейный слой с инпутом размера: размер изображения (28*28) + размер эмбеддинга меток (например, 10); и выходом 256\n",
        "2. LeakyReLU с alpha=0.01\n",
        "3. Полносвязный линейный слой с выходом 256\n",
        "4. LeakyReLU с alpha=0.01\n",
        "5. Полносвязный линейный слой с выходом 1\n",
        "6. Функция активации (какая?)\n",
        "\n",
        "LeakyRelu возвращает $f(x) = \\max(\\alpha x, x)$ с некой константой $\\alpha$; здесь коэффициент нелинейности равен $\\alpha=0.01$.\n",
        "\n",
        "Аутпут дискриминатора должен содержать число, соответствующее вероятности изображения быть подлинным.\n",
        "\n"
      ],
      "metadata": {
        "id": "JzeI7tQJCdsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        set_random_seed(42) # оставляем для воспроизводимости результатов\n",
        "        super().__init__()\n",
        "\n",
        "        # можно было закодировать one_hot, но мы захотели эмбеддинг меток\n",
        "        # эмбеддинг просто дает более богатое представление и иногда позволяет сэкономить несколько слоев сети.\n",
        "        # но здесь это не важно, будет работать что то, что то.\n",
        "        # везде в дальнейшем оставляем эмбеддинг\n",
        "        self.label_emb = nn.Embedding(10, 10)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # your code here\n",
        "        )\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        # В дискриминатор мы должны подать само изображение (28*28), склеенное с меткой\n",
        "        x = x.view(x.size(0), 784)\n",
        "        c = self.label_emb(labels)\n",
        "        x = torch.cat([x, c], 1) # и дискриминатор и генератор получают на вход информацию о метке\n",
        "        out = self.model(x)\n",
        "        return out.squeeze()"
      ],
      "metadata": {
        "id": "StzMc1AFYtzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWcXpcOVXgQx"
      },
      "source": [
        "### Генератор\n",
        "Теперь соберем, собственно, генератор\n",
        "1. Полносвязный линейный слой с инпутом размера: размер вектора шума (например, 100) + размер эмбеддинга меток (10); и выходом 1024\n",
        "2. ReLU\n",
        "3. Полносвязный линейный слой с выходом 1024\n",
        "4. ReLU\n",
        "5. Полносвязный линейный слой с выходом 784\n",
        "6. TanH - чтобы значения пикселей лежали в пределах [-1,1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise_dim=100):\n",
        "        set_random_seed(42)\n",
        "        super().__init__()\n",
        "\n",
        "        self.label_emb = nn.Embedding(10, 10)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # your code here\n",
        "        )\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        c = self.label_emb(labels)\n",
        "        x = torch.cat([z, c], 1) # и дискриминатор и генератор получают на вход информацию о метке\n",
        "        out = self.model(x)\n",
        "        return out.view(x.size(0), 28, 28) # разворачиваем линейный аутпут в картинку"
      ],
      "metadata": {
        "id": "XEX4qzFuZt1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В начале в качестве функции потерь будем использовать стандартный BCELoss"
      ],
      "metadata": {
        "id": "oGVZ3puKFU4a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ bce(s, y) = y * \\log(s) + (1 - y) * \\log(1 - s) $$"
      ],
      "metadata": {
        "id": "wwRdKPgJPRFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "4i6jKDwp47kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator().cuda()\n",
        "discriminator = Discriminator().cuda()"
      ],
      "metadata": {
        "id": "I2CqU9TwaKw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве оптимизатора будет использовать Adam с параметрами learning rate = 1e-3, betas = (0.5, 0.999)"
      ],
      "metadata": {
        "id": "kecXZHYvYKwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "?torch.optim.Adam"
      ],
      "metadata": {
        "id": "C_daa5CtL8Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_optimizer = # your code here\n",
        "\n",
        "g_optimizer = # your code here"
      ],
      "metadata": {
        "id": "9w6CVTiLaOLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Когда мы учим дискриминатор, мы передаем ему реальные объекты с метками + сгенерированные фейковые объекты с фейковыми метками, считаем loss по всем этим объектам, делаем backprop до весов дискриминатора и шаг по антиградиенту\n"
      ],
      "metadata": {
        "id": "SWZHSh1uGjzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_train_step(batch_size, discriminator, generator, d_optimizer, criterion, real_images, labels):\n",
        "    d_optimizer.zero_grad()\n",
        "\n",
        "    # Подлинные изображения\n",
        "    real_validity = discriminator(real_images, labels)\n",
        "    real_loss = criterion(real_validity, torch.ones(batch_size).cuda())\n",
        "\n",
        "    # Сгенерированные изображения\n",
        "    z = torch.randn(batch_size, 100).cuda() # генерируем шум\n",
        "    fake_labels = torch.LongTensor(np.random.randint(0, 10, batch_size)).cuda() # генерируем случайные метки для каждого изображения\n",
        "    fake_images = generator(z, fake_labels) # собираем в картинку\n",
        "    fake_validity = discriminator(fake_images, fake_labels) # дискриминатор будет сильно штрафовать генератор если тот сгенерил объект неправильно по метке.\n",
        "    fake_loss = criterion(fake_validity, torch.zeros(batch_size).cuda())\n",
        "\n",
        "    d_loss = real_loss + fake_loss\n",
        "    # your code here\n",
        "    # your code here\n",
        "    return d_loss.data"
      ],
      "metadata": {
        "id": "0NNGryv9aPt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь настроим шаг обучения генератора. Так же генерируем фейковые картинки и отдаем дискриминатору на оценку, считаем loss между уверенностью дискриминатора и единицами (чтобы оценить, насколько генератору удается обмануть дискриминатор), делаем backprop до весов генератора сквозь всю модель."
      ],
      "metadata": {
        "id": "ouQRd3mrmHGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion):\n",
        "    g_optimizer.zero_grad()\n",
        "    z = torch.randn(batch_size, 100).cuda()\n",
        "    fake_labels = torch.LongTensor(np.random.randint(0, 10, batch_size)).cuda()\n",
        "    fake_images = generator(z, fake_labels)\n",
        "    validity = discriminator(fake_images, fake_labels)\n",
        "    g_loss = criterion(validity, torch.ones(batch_size).cuda())\n",
        "    # your code here (loss backward)\n",
        "    # your code here (step optimizer)\n",
        "    return g_loss.data"
      ],
      "metadata": {
        "id": "ZItbfQSwaQq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тренируем наш GAN"
      ],
      "metadata": {
        "id": "hF1x2CTPo497"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "display_step = 300\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Starting epoch {epoch}...')\n",
        "    for i, (images, labels) in enumerate(data_loader):\n",
        "        real_images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        generator.train()\n",
        "        batch_size = real_images.size(0)\n",
        "        d_loss = discriminator_train_step(len(real_images), discriminator,\n",
        "                                          generator, d_optimizer, criterion,\n",
        "                                          real_images, labels)\n",
        "\n",
        "\n",
        "        g_loss = generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion)\n",
        "\n",
        "    generator.eval()\n",
        "    print(f'g_loss: {g_loss:.4f}, d_loss: {d_loss:.4f}')\n",
        "    z = torch.randn(9, 100).cuda()\n",
        "    labels = torch.LongTensor(np.arange(9)).cuda()\n",
        "    sample_images = generator(z, labels).unsqueeze(1).data.cpu()\n",
        "    grid = make_grid(sample_images, nrow=3, normalize=True).permute(1,2,0).numpy()\n",
        "    plt.imshow(grid)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "A5RhFLeraR2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Смотрим как генерируются изображения по запросу"
      ],
      "metadata": {
        "id": "AyJdYv1rNHkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.randn(100, 100).cuda()\n",
        "labels = torch.LongTensor([i for _ in range(10) for i in range(10)]).cuda()\n",
        "sample_images = generator(z, labels).unsqueeze(1).data.cpu()\n",
        "grid = make_grid(sample_images, nrow=10, normalize=True).permute(1,2,0).numpy()\n",
        "fig, ax = plt.subplots(figsize=(15,15))\n",
        "ax.imshow(grid)\n",
        "_ = plt.yticks([])\n",
        "_ = plt.xticks(np.arange(15, 300, 30), ['0', '1', '2', '3',\\\n",
        "                                        '4', '5', '6', '7', '8',\\\n",
        "                                        '9'], rotation=45, fontsize=20)"
      ],
      "metadata": {
        "id": "hPBeA6Lham3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сделайте вывод относительно качества генерируемых изображений такой архитектурой."
      ],
      "metadata": {
        "id": "5rftDKnxJiC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your conclusions here"
      ],
      "metadata": {
        "id": "Ye7kMaKCNYeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 2. Least Squares GAN\n",
        "Теперь мы рассмотрим [Least Squares GAN](https://arxiv.org/abs/1611.04076), новую, более стабильную альтернативу исходной функции потерь GAN.\n",
        "LSGAN использует квадратичную функцию потерь вместо логарифмической, чтобы стабилизировать обучение и избежать проблем с градиентами.\n",
        "\n",
        "В этой части нам нужно только изменить функцию потерь и переобучить модель. Мы будем реализовывать уравнение (9) из статьи, где функция потерь генератора имеет вид:\n",
        "\n",
        "Функция потерь генератора:\n",
        "$$\\ell_G  =  \\frac{1}{2}\\mathbb{E}_{z \\sim p(z)}\\left[\\left(D(G(z))-1\\right)^2\\right]$$\n",
        "Здесь мы хотим, чтобы дискриминатор $D(G(z))$ оценивал сгенерированные данные $G(z)$ как реальные (или близкие к 1)\n",
        "\n",
        "Функция потерь дискриминатора\n",
        "$$ \\ell_D = \\frac{1}{2}\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\left(D(x)-1\\right)^2\\right] + \\frac{1}{2}\\mathbb{E}_{z \\sim p(z)}\\left[ \\left(D(G(z))\\right)^2\\right]$$\n",
        "Теперь мы хотим, чтобы дискриминатор оценивал реальные данные $D(x)$ как подлинные, а аутпут генератора $D(G(z))$ - как фейк\n",
        "\n",
        "\n",
        "**Замечание**: Вместо расчета матожидания $\\mathbb{E}$ будем брать среднее значение по элементам минибатча `torch.mean`. В качестве результатов дискриминатора $D(x)$ и $D(G(z))$ используем прямой атупут генератора (`scores_real` and `scores_fake`)."
      ],
      "metadata": {
        "id": "L9uGpNl9J3K8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ls_discriminator_loss(scores_real, scores_fake):\n",
        "    \"\"\"\n",
        "    Compute the Least-Squares GAN loss for the discriminator.\n",
        "\n",
        "    Inputs:\n",
        "    - scores_real: PyTorch Variable of shape (N,) giving scores for the real data.\n",
        "    - scores_fake: PyTorch Variable of shape (N,) giving scores for the fake data.\n",
        "\n",
        "    Outputs:\n",
        "    - loss: A PyTorch Variable containing the loss.\n",
        "    \"\"\"\n",
        "    N = scores_real.size()\n",
        "    loss = (0.5 * torch.mean((scores_real-torch.ones(N).cuda())**2)) + (0.5 * torch.mean(scores_fake**2))\n",
        "    return loss\n",
        "\n",
        "def ls_generator_loss(scores_fake):\n",
        "    \"\"\"\n",
        "    Computes the Least-Squares GAN loss for the generator.\n",
        "\n",
        "    Inputs:\n",
        "    - scores_fake: PyTorch Variable of shape (N,) giving scores for the fake data.\n",
        "\n",
        "    Outputs:\n",
        "    - loss: A PyTorch Variable containing the loss.\n",
        "    \"\"\"\n",
        "    N = scores_fake.size()\n",
        "    loss = (0.5 * torch.mean((scores_fake-torch.ones(N).cuda())**2))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "emXfed0ohad4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator().cuda()\n",
        "discriminator = Discriminator().cuda()"
      ],
      "metadata": {
        "id": "iQQCpd4DYvEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавим значения бетта 1 и бетта 2 к Адаму, без этого изменения дискриминатор очень быстро достигает значения 0 и генератор не учится"
      ],
      "metadata": {
        "id": "PmDXF8eLY1WF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1e-3, betas = (0.5, 0.999))\n",
        "g_optimizer = torch.optim.Adam(generator.parameters(), lr=1e-3, betas = (0.5, 0.999))"
      ],
      "metadata": {
        "id": "NnBRHwkgd4FZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ls_discriminator_train_step(batch_size, discriminator, generator, d_optimizer, criterion, real_images, labels):\n",
        "    d_optimizer.zero_grad()\n",
        "\n",
        "    # Тренировка на подлинных изображениях\n",
        "    real_validity = discriminator(real_images, labels)\n",
        "\n",
        "    # Тренировка на фейковых изображениях\n",
        "    z = torch.randn(batch_size, 100).cuda()\n",
        "    fake_labels = torch.LongTensor(np.random.randint(0, 10, batch_size)).cuda()\n",
        "    fake_images = generator(z, fake_labels)\n",
        "    fake_validity = discriminator(fake_images, fake_labels) # дискриминатор будет сильно штрафовать генератор если тот сгенерил объект неправильно по метке.\n",
        "\n",
        "    d_loss = # your code here\n",
        "\n",
        "    # your code here\n",
        "    # your code here\n",
        "    return d_loss.data"
      ],
      "metadata": {
        "id": "tBmq_YLbd9ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ls_generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion):\n",
        "    g_optimizer.zero_grad()\n",
        "\n",
        "    z = torch.randn(batch_size, 100).cuda()\n",
        "    fake_labels = torch.LongTensor(np.random.randint(0, 10, batch_size)).cuda()\n",
        "    fake_images = generator(z, fake_labels)\n",
        "    validity = discriminator(fake_images, fake_labels)\n",
        "    g_loss = # your code here\n",
        "    # your code here\n",
        "    # your code here\n",
        "    return g_loss.data"
      ],
      "metadata": {
        "id": "J_u2-fS1eAVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "display_step = 300\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Starting epoch {epoch}...')\n",
        "    for i, (images, labels) in enumerate(data_loader):\n",
        "        real_images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        generator.train()\n",
        "        batch_size = real_images.size(0)\n",
        "        d_loss = # your code here\n",
        "\n",
        "\n",
        "        g_loss = # your code here\n",
        "\n",
        "    generator.eval()\n",
        "    print(f'g_loss: {g_loss:.4f}, d_loss: {d_loss:.4f}')\n",
        "    z = torch.randn(9, 100).cuda()\n",
        "    labels = torch.LongTensor(np.arange(9)).cuda()\n",
        "    sample_images = generator(z, labels).unsqueeze(1).data.cpu()\n",
        "    grid = make_grid(sample_images, nrow=3, normalize=True).permute(1,2,0).numpy()\n",
        "    plt.imshow(grid)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "90TP7rYQeqeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.randn(100, 100).cuda()\n",
        "labels = torch.LongTensor([i for _ in range(10) for i in range(10)]).cuda()\n",
        "sample_images = generator(z, labels).unsqueeze(1).data.cpu()\n",
        "grid = make_grid(sample_images, nrow=10, normalize=True).permute(1,2,0).numpy()\n",
        "fig, ax = plt.subplots(figsize=(15,15))\n",
        "ax.imshow(grid)\n",
        "_ = plt.yticks([])\n",
        "_ = plt.xticks(np.arange(15, 300, 30), ['0', '1', '2', '3',\\\n",
        "                                        '4', '5', '6', '7', '8',\\\n",
        "                                        '9'], rotation=45, fontsize=20)"
      ],
      "metadata": {
        "id": "70g7zmeon6Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Улучшилось ли качество генерируемых изображений?"
      ],
      "metadata": {
        "id": "s4rcmvZ0Qpfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your conclusions here"
      ],
      "metadata": {
        "id": "cgtQgViCQtja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q73LS7TcXgQu"
      },
      "source": [
        "## Задание 2.1. Чувствительность к гиперпараметрам\n",
        "\n",
        " Одной из проблем при работе с GAN является очень высокая чувствительность к настройке гиперпараметров. Попробуйте для нашего простого GAN с функцией потерь LSGAN использовать оптимизаторы Adam с learning rate = 1e-4 и дефолтными скользящими параметрами betas.\n",
        "\n",
        "Обучается ли модель?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your try here"
      ],
      "metadata": {
        "id": "A79JUEMC5_Ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydKmyfrxXgQ5"
      },
      "source": [
        "# Задание 3. Deeply Convolutional GAN\n",
        "\n",
        "В первом задании мы реализовали почти точную копию оригинальной GAN-сети. Однако эта архитектура не позволяет получить представления об изображении в пространстве пикселей. Она не способна учитывать такие вещи, как например \"резкие края\", потому что в ней отсутствуют какие-либо сверточные слои. Поэтому в этом разделе попробуем воссоздать архитектуру [DCGAN](https://arxiv.org/abs/1511.06434), где используются сверточные сети.\n",
        "\n",
        "\n",
        "### Дискриминатор\n",
        "Мы хотим присоединять метку класса к объекту. Не очевидным является то, как присоединить ээмбеддинг метки к объекту - картинке. Поэтому давайте разобьем архитектуру дискриминатора на 2 блока: CNN блок и full connected блок. После прогона объекта через CNN блок и разворотом во Flatten, будем добавлять метку и передавать далее в full connected блок.\n",
        "\n",
        "CNN блок:\n",
        "* Преобразовать \"линейку\", получаемую от генератора, в тензор изображения размера 1x28x28 (используйте nn.Unflatten)\n",
        "* Conv2D, 32 фичи (выходных канала), ядро 5x5 с шагом (stride) 1, функция активации Leaky ReLU (alpha=0.01)\n",
        "* MaxPool2D, ядро 2x2 с шагом 2\n",
        "* Conv2D, 64 фичи, ядро 5x5 с шагом 1, Leaky ReLU (alpha=0.01)\n",
        "* MaxPool2D, ядро 2x2 с шагом 2\n",
        "* Flatten слой\n",
        "\n",
        "Full connected блок:\n",
        "* Полносвязный слой со входом 4 x 4 x 64 + 10 (посчитан из результата конволюций + размер меток) и таким же выходом, Leaky ReLU (alpha=0.01)\n",
        "* Полносвязный слой с выходом  1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DiscriminatorV2(nn.Module):\n",
        "    def __init__(self):\n",
        "        set_random_seed(42)\n",
        "        super().__init__()\n",
        "\n",
        "        self.label_emb = nn.Embedding(10, 10)\n",
        "\n",
        "        self.cnn = nn.Sequential(\n",
        "            # your code here\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            # your code here\n",
        "        )\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        x = x.view(x.size(0), 784)\n",
        "        c = self.label_emb(labels)\n",
        "        x = self.cnn(x) # все конволюции и Flatten\n",
        "        x = torch.cat([x, c], 1) # приклеиваем метку к объекту уже после прогона через CNN слой\n",
        "        x = self.fc(x) # все после Flatten\n",
        "        return x.squeeze()"
      ],
      "metadata": {
        "id": "v5VdaS4GeumY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g18ulJUXgQ5"
      },
      "source": [
        "### Генератор\n",
        "Для генератора мы точно скопируем архитектуру из статьи [InfoGAN paper](https://arxiv.org/pdf/1606.03657.pdf)\n",
        "\n",
        "* Полносвязный слой со входом 100 + 10 (шум + метки) и выходом 1024, ReLU\n",
        "* BatchNorm1d\n",
        "* Полносвязный слой с выходом 128 x 7 x 7, ReLU\n",
        "* BatchNorm1d\n",
        "* Разворот в тензор картинки 128x7x7 (nn.Unflatten)\n",
        "* Обратная свертка ([nn.ConvTranspose2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose)), 64 фичи, ядро 4x4 с шагом 2 и 'same' падингом, ReLU\n",
        "* BatchNorm2d\n",
        "* Обратная свертка с 1 фичей, ядро 4x4 с шагом 2 и 'same' падингом, TanH\n",
        "* Должна получиться картинка 28x28 с 1 каналом, разворачиваем в вектор длины 784 (Flatten слой)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GeneratorV2(nn.Module):\n",
        "    def __init__(self, noise_dim=100):\n",
        "        set_random_seed(42)\n",
        "        super().__init__()\n",
        "\n",
        "        self.label_emb = nn.Embedding(10, 10)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # your code here\n",
        "        )\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        c = self.label_emb(labels)\n",
        "        x = torch.cat([z, c], 1)\n",
        "        out = self.model(x)\n",
        "        return out.view(x.size(0), 28, 28)"
      ],
      "metadata": {
        "id": "VfjefM6QoB3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = GeneratorV2().cuda()\n",
        "discriminator = DiscriminatorV2().cuda()"
      ],
      "metadata": {
        "id": "SqSM-rJMoQif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_optimizer = # your code here\n",
        "g_optimizer = # your code here"
      ],
      "metadata": {
        "id": "t-XNaUIzsYs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "display_step = 300\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Starting epoch {epoch}...')\n",
        "    for i, (images, labels) in enumerate(data_loader):\n",
        "        real_images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        generator.train()\n",
        "        batch_size = real_images.size(0)\n",
        "        d_loss = ls_discriminator_train_step(len(real_images), discriminator,\n",
        "                                          generator, d_optimizer, criterion,\n",
        "                                          real_images, labels)\n",
        "\n",
        "\n",
        "        g_loss = ls_generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion)\n",
        "\n",
        "    generator.eval()\n",
        "    print(f'g_loss: {g_loss:.4f}, d_loss: {d_loss:.4f}')\n",
        "    z = torch.randn(9, 100).cuda()\n",
        "    labels = torch.LongTensor(np.arange(9)).cuda()\n",
        "    sample_images = generator(z, labels).unsqueeze(1).data.cpu()\n",
        "    grid = make_grid(sample_images, nrow=3, normalize=True).permute(1,2,0).numpy()\n",
        "    plt.imshow(grid)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-tGVsJVhoU29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.randn(100, 100).cuda()\n",
        "labels = torch.LongTensor([i for _ in range(10) for i in range(10)]).cuda()\n",
        "sample_images = generator(z, labels).unsqueeze(1).data.cpu()\n",
        "grid = make_grid(sample_images, nrow=10, normalize=True).permute(1,2,0).numpy()\n",
        "fig, ax = plt.subplots(figsize=(15,15))\n",
        "ax.imshow(grid)\n",
        "_ = plt.yticks([])\n",
        "_ = plt.xticks(np.arange(15, 300, 30), ['0', '1', '2', '3',\\\n",
        "                                        '4', '5', '6', '7', '8',\\\n",
        "                                        '9'], rotation=45, fontsize=20)"
      ],
      "metadata": {
        "id": "jplE0AhExyWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сравните результаты обучения двух архитектур (простой начальной и DCGAN). Какие выводы можно сделать?"
      ],
      "metadata": {
        "id": "cwWdHnpZibTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your conclusions here"
      ],
      "metadata": {
        "id": "_FaulTieW5f_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}