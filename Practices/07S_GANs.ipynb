{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Existanze54/sirius-neural-networks-2024/blob/main/Practices/07S_GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q54dMaVlXAM"
      },
      "source": [
        "# Предсказание сайтов сплайсинга\n",
        "\n",
        "Сплайсинг $-$ происходящее в ходе процессинга РНК вырезание определённых нуклеотидных последовательностей (интронов) из молекул РНК и соединения оставшихся последовательностей, сохраняющихся в «зрелой» молекуле (экзонов).\n",
        "Участвующие в процессе сплайсинга белки распознают границы интронов благодаря наличию в последовательности донорных (5') и акцепторных (3') сайтов.\n",
        "\n",
        "Уже знакомый нам датасет из <a href=\"https://www.kaggle.com/muhammetvarl/splicejunction-gene-sequences-dataset\">Kaggle</a> содержит закодированные последовательности РНК, размеченные на 3 класса: содержит донорный сайт, содержит акцепторный сайт, и не содержит таких сайтов. Воспользуемся им для изучения возможностей RNN.\n",
        "\n",
        "\n",
        "<img src=\"https://kodomo.fbb.msu.ru/FBB/year_20/ml/rnn/splicing.gif\" alt=\"Drawing\" width= \"500px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_neRHs3EzTJu"
      },
      "source": [
        "Датасет представлен закодированными в бинарном формате последовательностями длиной 60, по три \"признака\" на нуклеотид (всего 180 фичей):\n",
        "\n",
        "* A $\\rightarrow$ 1 0 0\n",
        "* C $\\rightarrow$ 0 1 0\n",
        "* G $\\rightarrow$ 0 0 1\n",
        "* U $\\rightarrow$ 0 0 0\n",
        "\n",
        "Так можно делать, но torch позволяет нам делать хитрее. Для каждого из трех \"признаков\" отведем свою размерность, таким образом сведя датасет $N * 180$ к $N * 60 * 3$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErHWkELb1pMC"
      },
      "source": [
        "Загрузим датасет:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7sLrQRhl4Cv"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADCV2JKOvJ4a",
        "outputId": "d68d4a62-f2f0-4c51-a40e-d6bd944c9e2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!if [ ! -f ./rna.csv ]; then wget https://kodomo.fbb.msu.ru/FBB/year_20/ml/rnn/rna.csv; fi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-14 16:15:45--  https://kodomo.fbb.msu.ru/FBB/year_20/ml/rnn/rna.csv\n",
            "Resolving kodomo.fbb.msu.ru (kodomo.fbb.msu.ru)... 93.180.63.127\n",
            "Connecting to kodomo.fbb.msu.ru (kodomo.fbb.msu.ru)|93.180.63.127|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1154490 (1.1M) [text/csv]\n",
            "Saving to: ‘rna.csv’\n",
            "\n",
            "rna.csv             100%[===================>]   1.10M   956KB/s    in 1.2s    \n",
            "\n",
            "2022-12-14 16:15:49 (956 KB/s) - ‘rna.csv’ saved [1154490/1154490]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "ml8gaHuWlWkG",
        "outputId": "a03f4332-752c-4fef-8362-e3413617b3e7"
      },
      "source": [
        "df = pd.read_csv(\"rna.csv\")\n",
        "\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3186, 181)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A0</th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "      <th>A9</th>\n",
              "      <th>A10</th>\n",
              "      <th>A11</th>\n",
              "      <th>A12</th>\n",
              "      <th>A13</th>\n",
              "      <th>A14</th>\n",
              "      <th>A15</th>\n",
              "      <th>A16</th>\n",
              "      <th>A17</th>\n",
              "      <th>A18</th>\n",
              "      <th>A19</th>\n",
              "      <th>A20</th>\n",
              "      <th>A21</th>\n",
              "      <th>A22</th>\n",
              "      <th>A23</th>\n",
              "      <th>A24</th>\n",
              "      <th>A25</th>\n",
              "      <th>A26</th>\n",
              "      <th>A27</th>\n",
              "      <th>A28</th>\n",
              "      <th>A29</th>\n",
              "      <th>A30</th>\n",
              "      <th>A31</th>\n",
              "      <th>A32</th>\n",
              "      <th>A33</th>\n",
              "      <th>A34</th>\n",
              "      <th>A35</th>\n",
              "      <th>A36</th>\n",
              "      <th>A37</th>\n",
              "      <th>A38</th>\n",
              "      <th>A39</th>\n",
              "      <th>...</th>\n",
              "      <th>A141</th>\n",
              "      <th>A142</th>\n",
              "      <th>A143</th>\n",
              "      <th>A144</th>\n",
              "      <th>A145</th>\n",
              "      <th>A146</th>\n",
              "      <th>A147</th>\n",
              "      <th>A148</th>\n",
              "      <th>A149</th>\n",
              "      <th>A150</th>\n",
              "      <th>A151</th>\n",
              "      <th>A152</th>\n",
              "      <th>A153</th>\n",
              "      <th>A154</th>\n",
              "      <th>A155</th>\n",
              "      <th>A156</th>\n",
              "      <th>A157</th>\n",
              "      <th>A158</th>\n",
              "      <th>A159</th>\n",
              "      <th>A160</th>\n",
              "      <th>A161</th>\n",
              "      <th>A162</th>\n",
              "      <th>A163</th>\n",
              "      <th>A164</th>\n",
              "      <th>A165</th>\n",
              "      <th>A166</th>\n",
              "      <th>A167</th>\n",
              "      <th>A168</th>\n",
              "      <th>A169</th>\n",
              "      <th>A170</th>\n",
              "      <th>A171</th>\n",
              "      <th>A172</th>\n",
              "      <th>A173</th>\n",
              "      <th>A174</th>\n",
              "      <th>A175</th>\n",
              "      <th>A176</th>\n",
              "      <th>A177</th>\n",
              "      <th>A178</th>\n",
              "      <th>A179</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 181 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   A0  A1  A2  A3  A4  A5  A6  ...  A174  A175  A176  A177  A178  A179  class\n",
              "0   0   1   0   0   0   0   1  ...     0     0     1     1     0     0      3\n",
              "1   0   0   1   0   0   1   0  ...     1     0     0     0     1     0      3\n",
              "2   0   0   1   0   0   1   0  ...     0     0     1     0     0     1      3\n",
              "3   0   0   0   0   0   0   0  ...     0     0     1     0     0     1      1\n",
              "4   0   1   0   0   0   0   0  ...     0     1     0     1     0     0      2\n",
              "\n",
              "[5 rows x 181 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEZQIvusDfJY",
        "outputId": "6d08b010-363e-442b-d5af-6259a5552b8b"
      },
      "source": [
        "df[\"class\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    1654\n",
              "1     767\n",
              "2     765\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqi1YA0L1oIn"
      },
      "source": [
        "Приведем метки классов к нормальному виду:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpIp6h74lWmA",
        "outputId": "14ebd1e4-7d75-4686-e2cf-a48d823a6cf9"
      },
      "source": [
        "y = df[\"class\"]\n",
        "X = df.drop(['class'], axis=1)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Encode class values as integers and perform label-encoding\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y)\n",
        "y = encoder.transform(y)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, ..., 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.classes_"
      ],
      "metadata": {
        "id": "Q0JgRaaqVcnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6doTu9k1wSv"
      },
      "source": [
        "## Задание 1\n",
        "\n",
        "Поменяйте размерность датасета: от $N * 180$ к $N * 3 * 60$. Вам поможет <a href='https://pytorch.org/docs/stable/generated/torch.Tensor.reshape.html'>torch.Tensor.reshape<a/>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND3k5RMjlWoF"
      },
      "source": [
        "# Train-Test\n",
        "from sklearn.model_selection import train_test_split\n",
        "# shuffle and split training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
        "                                                    random_state=0)\n",
        "\n",
        "# torch.tensor infers the dtype automatically, while torch.Tensor returns a torch.FloatTensor.\n",
        "X_train = torch.Tensor(X_train.values)\n",
        "X_train = X_train.reshape((#put your code here))\n",
        "y_train = torch.Tensor(y_train)\n",
        "y_train = y_train.type(torch.LongTensor)\n",
        "\n",
        "X_test = torch.Tensor(X_test.values)\n",
        "\n",
        "X_test = X_test.reshape((#put your code here))\n",
        "\n",
        "y_test = torch.Tensor(y_test)\n",
        "y_test = y_test.type(torch.LongTensor)\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMVGewAv2UtP"
      },
      "source": [
        "## Задание 2\n",
        "\n",
        "Реализуйте класс spliceJuncPredictor. Нейросеть должна содержать 1 рекуррентный слой и 1 полносвязный. Укажите batch_first=True.  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "Qk8R1xDJUW9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "?nn.RNN"
      ],
      "metadata": {
        "id": "onsz45KLUXkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ueo9wPiplWp4"
      },
      "source": [
        "class spliceJuncPredictor(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.rnn = #put your code here\n",
        "        self.fc = #put your code here\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, h = self.rnn(x)\n",
        "        y = self.fc(h)\n",
        "        return y[0], h # убираем \"лишнюю\" размерность"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv4wKgP03Jux"
      },
      "source": [
        "Проверьте, что сеть правильно работает и возвращает тензор нужной размерности (*какой?*). Размерность скрытого слоя можете подобрать по желанию."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM1mHWWgEkzb",
        "outputId": "54ff70f7-f290-4d4e-9ae7-994679a75bf7"
      },
      "source": [
        "input_size = 3\n",
        "hidden_size = 16\n",
        "rnn = spliceJuncPredictor(input_size, hidden_size)\n",
        "\n",
        "out, h = rnn(X_train)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2230, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjq0CP8_3ezR"
      },
      "source": [
        "Воспользуйтесть кодом и обучите сеть. Оцените качество пресказания."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data_utils\n",
        "\n",
        "EPOCHS_NUM = 150\n",
        "BATCH_SIZE = 400\n",
        "\n",
        "train_loader = data_utils.DataLoader(data_utils.TensorDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = data_utils.DataLoader(data_utils.TensorDataset(X_test, y_test), batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "7miLlCw0ZaEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPXMH88oEk1b"
      },
      "source": [
        "def validate(model,testloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for features, labels in testloader:\n",
        "            outputs, h = model(features)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "def train(model, num_epochs, learning_rate = 0.01):\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # Train the model\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for feat_batch, labels_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs, h = model(feat_batch)\n",
        "            loss = criterion(outputs, labels_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        accuracy = validate(model,test_loader)\n",
        "        if epoch % 25 == 0:\n",
        "            print(f\"Epoch {epoch} Loss {loss.item():.2f} Accuracy {accuracy:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = spliceJuncPredictor(input_size, hidden_size)\n",
        "train(rnn, num_epochs=EPOCHS_NUM)"
      ],
      "metadata": {
        "id": "VWxK57djWL23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOWXXuOAWxiP"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def get_report(model, X_test, y_test):\n",
        "    model.eval()\n",
        "    outputs, h = model(X_test)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    model_report = classification_report(y_test, predicted)\n",
        "    print(model_report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyMDZ7JlWxp2"
      },
      "source": [
        "get_report(rnn, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OMt262A5rwr"
      },
      "source": [
        "## Задание 3\n",
        "\n",
        "Замените RNN слой на <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\">GRU</a> или <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\">LSTM</a> (на выбор). Внесите необходимые изменения. Обучите сеть, оцените качество предсказания."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yStW3jomWLH"
      },
      "source": [
        "#put your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbuwpSKYmn3A"
      },
      "source": [
        "#put your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcZ_7pX0Ydec"
      },
      "source": [
        "# Генерация изображений\n",
        "\n",
        "Попробуем сгенерировать новые изображения, обучив простую генеративно-состязательную сеть на датасете [FashionMNIST](https://www.kaggle.com/zalando-research/fashionmnist) -- датасете изображений предметов одежды размером 28*28."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTVyoqFEYdu7"
      },
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "from torch import autograd\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mGBFoN4YdxI"
      },
      "source": [
        "from torchvision.transforms import ToTensor, Normalize, Compose\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "#Load the data\n",
        "\n",
        "mnist = FashionMNIST(root='data',\n",
        "              train=True,\n",
        "              download=True,\n",
        "              transform=Compose([ToTensor(), Normalize(mean=(0.5,), std=(0.5,))]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCrsVAS0yiCY"
      },
      "source": [
        "def denorm(x):\n",
        "    out = (x + 1) / 2\n",
        "    return out.clamp(0, 1)\n",
        "\n",
        "img, label = mnist[0]\n",
        "print('Label: ', label)\n",
        "img_norm = denorm(img)\n",
        "plt.imshow(img_norm[0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBxycvXVl7tf"
      },
      "source": [
        "data_loader = torch.utils.data.DataLoader(mnist, batch_size=64, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 4.\n",
        "\n",
        "Напишите полносвязный cGAN. В данном случае условие это lablel (номер класса) предмета одежды.\n",
        "\n",
        "1. Сделайте эмбеддинг для лэйблов внутри модели\n",
        "2. С помощью torch.cat добавьте этот эмбеддинг ко входу генератора и дискриминатора. Входное латентное пространство зададим, например, размера 100.\n",
        "\n",
        "Ниже приведены рекомендованные для этого задания архитектуры сетей. Используйте их, вносите изменения по желанию.\n",
        "\n",
        "3. Используйте следующую для генератора:\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(?, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, 784),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        \n",
        "4. Используйте такую архитектуру для дискриминатора:\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(?, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )"
      ],
      "metadata": {
        "id": "VN--dNcJ_JeX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRW1lz-tl7v1"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.label_emb = nn.Embedding(10, 10)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            ## put some code here ##\n",
        "        )\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        x = x.view(x.size(0), 784)\n",
        "        c = self.label_emb(labels)\n",
        "        ## Change ?? in the next line\n",
        "        x = torch.cat([??, ??], 1)\n",
        "        ##\n",
        "        out = self.model(x)\n",
        "        return out.squeeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VypaidsTl70j"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.label_emb = nn.Embedding(10, 10)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            ## put some code here ##\n",
        "        )\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        z = z.view(z.size(0), 100)\n",
        "        c = self.label_emb(labels)\n",
        "        ## Change ?? in the next line\n",
        "        x = torch.cat([??, ??], 1)\n",
        "        ##\n",
        "        out = self.model(x)\n",
        "        return out.view(x.size(0), 28, 28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим модель."
      ],
      "metadata": {
        "id": "atcuSKVnHpGN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7QDHMcZl73O"
      },
      "source": [
        "generator = Generator().cuda()\n",
        "discriminator = Discriminator().cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLJVLgV2mzM8"
      },
      "source": [
        "criterion = nn.BCELoss()\n",
        "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1e-4)\n",
        "g_optimizer = torch.optim.Adam(generator.parameters(), lr=1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9N6Frt8mzQ9"
      },
      "source": [
        "def discriminator_train_step(batch_size, discriminator, generator, d_optimizer, criterion, real_images, labels):\n",
        "    d_optimizer.zero_grad()\n",
        "\n",
        "    # train with real images\n",
        "    real_validity = discriminator(real_images, labels)\n",
        "    real_loss = criterion(real_validity, torch.ones(batch_size).cuda())\n",
        "\n",
        "    # train with fake images\n",
        "    z = torch.randn(batch_size, 100).cuda()\n",
        "    fake_labels = torch.LongTensor(np.random.randint(0, 10, batch_size)).cuda()\n",
        "    fake_images = generator(z, fake_labels)\n",
        "    fake_validity = discriminator(fake_images, fake_labels)\n",
        "    fake_loss = criterion(fake_validity, torch.zeros(batch_size).cuda())\n",
        "\n",
        "    d_loss = real_loss + fake_loss\n",
        "    d_loss.backward()\n",
        "    d_optimizer.step()\n",
        "    return d_loss.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pl-_VdBmzO8"
      },
      "source": [
        "def generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion):\n",
        "    g_optimizer.zero_grad()\n",
        "    z = torch.randn(batch_size, 100).cuda()\n",
        "    fake_labels = torch.LongTensor(np.random.randint(0, 10, batch_size)).cuda()\n",
        "    fake_images = generator(z, fake_labels)\n",
        "    validity = discriminator(fake_images, fake_labels)\n",
        "    g_loss = criterion(validity, torch.ones(batch_size).cuda())\n",
        "    g_loss.backward()\n",
        "    g_optimizer.step()\n",
        "    return g_loss.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVkHHQ9bmzUt"
      },
      "source": [
        "num_epochs = 30\n",
        "n_critic = 5\n",
        "display_step = 300\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Starting epoch {epoch}...')\n",
        "    for i, (images, labels) in enumerate(data_loader):\n",
        "        real_images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        generator.train()\n",
        "        batch_size = real_images.size(0)\n",
        "        d_loss = discriminator_train_step(len(real_images), discriminator,\n",
        "                                          generator, d_optimizer, criterion,\n",
        "                                          real_images, labels)\n",
        "\n",
        "\n",
        "        g_loss = generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion)\n",
        "\n",
        "    generator.eval()\n",
        "    print(f'g_loss: {g_loss:.4f}, d_loss: {d_loss:.4f}')\n",
        "    z = torch.randn(9, 100).cuda()\n",
        "    labels = torch.LongTensor(np.arange(9)).cuda()\n",
        "    sample_images = generator(z, labels).unsqueeze(1).data.cpu()\n",
        "    grid = make_grid(sample_images, nrow=3, normalize=True).permute(1,2,0).numpy()\n",
        "    plt.imshow(grid)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем сгенерировать по несколько предметов каждого класса."
      ],
      "metadata": {
        "id": "bLAglmmCHyCa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1q_391HmzWc"
      },
      "source": [
        "z = torch.randn(100, 100).cuda()\n",
        "labels = torch.LongTensor([i for _ in range(10) for i in range(10)]).cuda()\n",
        "sample_images = generator(z, labels).unsqueeze(1).data.cpu()\n",
        "grid = make_grid(sample_images, nrow=10, normalize=True).permute(1,2,0).numpy()\n",
        "fig, ax = plt.subplots(figsize=(15,15))\n",
        "ax.imshow(grid)\n",
        "_ = plt.yticks([])\n",
        "_ = plt.xticks(np.arange(15, 300, 30), ['T-Shirt', 'Trouser', 'Pullover', 'Dress',\\\n",
        "                                        'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag',\\\n",
        "                                        'Ankle boot'], rotation=45, fontsize=20)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}